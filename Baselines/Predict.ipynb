{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type=\"GPU\")\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type=\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(device=gpus[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pruth\\\\Desktop\\\\New folder'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "#os.chdir('C:\\\\Users\\\\narayanan\\\\Desktop\\\\dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-3.0.0-cp38-cp38-win_amd64.whl (12.7 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from pyarrow) (1.19.2)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-3.0.0\n",
      "Collecting mmcv\n",
      "  Downloading mmcv-1.2.7.tar.gz (231 kB)\n",
      "Collecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (1.19.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (8.0.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (5.3.1)\n",
      "Requirement already satisfied: yapf in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (0.30.0)\n",
      "Collecting opencv-python>=3\n",
      "  Downloading opencv_python-4.5.1.48-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: regex in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (2020.10.15)\n",
      "Building wheels for collected packages: mmcv\n",
      "  Building wheel for mmcv (setup.py): started\n",
      "  Building wheel for mmcv (setup.py): finished with status 'done'\n",
      "  Created wheel for mmcv: filename=mmcv-1.2.7-py2.py3-none-any.whl size=336567 sha256=dbff499b2a81b440f4b41d4ad6f18a73858cc808badfeba91f1ab1f0179152b3\n",
      "  Stored in directory: c:\\users\\pruth\\appdata\\local\\pip\\cache\\wheels\\15\\9c\\42\\c30611ff05230151d3c24da668d57afcedaffd95db49a87b8b\n",
      "Successfully built mmcv\n",
      "Installing collected packages: opencv-python, addict, mmcv\n",
      "Successfully installed addict-2.4.0 mmcv-1.2.7 opencv-python-4.5.1.48\n",
      "Collecting facenet_pytorch\n",
      "  Using cached facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from facenet_pytorch) (1.19.2)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.9.0-cp38-cp38-win_amd64.whl (852 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from facenet_pytorch) (2.24.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from facenet_pytorch) (8.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (1.25.11)\n",
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp38-cp38-win_amd64.whl (190.5 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\users\\\\pruth\\\\anaconda3\\\\Lib\\\\site-packages\\\\torch\\\\distributed\\\\nn\\\\api\\\\remote_module.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from torch==1.8.0->torchvision->facenet_pytorch) (3.7.4.3)\n",
      "Installing collected packages: torch, torchvision, facenet-pytorch\n",
      "Requirement already satisfied: mmcv in c:\\users\\pruth\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: yapf in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (0.30.0)\n",
      "Requirement already satisfied: addict in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (2.4.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (5.3.1)\n",
      "Requirement already satisfied: opencv-python>=3 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (4.5.1.48)\n",
      "Requirement already satisfied: regex in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (2020.10.15)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (8.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from mmcv) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet_pytorch\n",
    "!pip install mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facenet_pytorch\n",
      "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: pillow in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from facenet_pytorch) (8.0.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.9.0-cp38-cp38-win_amd64.whl (852 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from facenet_pytorch) (1.19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from facenet_pytorch) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (2.10)\n",
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp38-cp38-win_amd64.whl (190.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pruth\\anaconda3\\lib\\site-packages (from torch==1.8.0->torchvision->facenet_pytorch) (3.7.4.3)\n",
      "Installing collected packages: torch, torchvision, facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.2 torch-1.8.0 torchvision-0.9.0\n",
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Running on device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceExtractor:\n",
    "    def __init__(self, detector, n_frames=None, resize=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            n_frames {int} -- Total number of frames to load. These will be evenly spaced\n",
    "                throughout the video. If not specified (i.e., None), all frames will be loaded.\n",
    "                (default: {None})\n",
    "            resize {float} -- Fraction by which to resize frames from original prior to face\n",
    "                detection. A value less than 1 results in downsampling and a value greater than\n",
    "                1 result in upsampling. (default: {None})\n",
    "        \"\"\"\n",
    "\n",
    "        self.detector = detector\n",
    "        self.n_frames = n_frames\n",
    "        self.resize = resize\n",
    "    \n",
    "    def __call__(self, filename, save_dir):\n",
    "        \"\"\"Load frames from an MP4 video, detect faces and save the results.\n",
    "\n",
    "        Parameters:\n",
    "            filename {str} -- Path to video.\n",
    "            save_dir {str} -- The directory where results are saved.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create video reader and find length\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Pick 'n_frames' evenly spaced frames to sample\n",
    "        if self.n_frames is None:\n",
    "            sample = np.arange(0, v_len)\n",
    "        else:\n",
    "            sample = np.linspace(0, v_len - 1, self.n_frames).astype(int)\n",
    "\n",
    "        # Loop through frames\n",
    "        for j in range(v_len):\n",
    "            success = v_cap.grab()\n",
    "            if j in sample:\n",
    "                # Load frame\n",
    "                success, frame = v_cap.retrieve()\n",
    "                if not success:\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = Image.fromarray(frame)\n",
    "                \n",
    "                # Resize frame to desired size\n",
    "                if self.resize is not None:\n",
    "                    frame = frame.resize([int(d * self.resize) for d in frame.size])\n",
    "\n",
    "                save_path = os.path.join(save_dir, f'{j}.png')\n",
    "\n",
    "                self.detector([frame], save_path=save_path)\n",
    "\n",
    "        v_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = MTCNN(margin=14, keep_all=True, factor=0.5, device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_extractor = FaceExtractor(detector=face_detector, n_frames=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pruth\\\\Desktop\\\\New folder\\\\test\\\\'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the directory path in which video is \n",
    "TRAIN_DIR = os.getcwd()+'\\\\test\\\\'\n",
    "TRAIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\pruth\\\\Desktop\\\\New folder\\\\test\\\\001.mp4']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_videos = glob.glob(os.path.join(TRAIN_DIR, '*.mp4'))\n",
    "all_train_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DIR =os.getcwd()+'\\\\temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6535b019fdb843b4baed85d2d0a30686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for path in tqdm(all_train_videos):\n",
    "        file_name = path.split('/')[-1]\n",
    "\n",
    "        save_dir = os.path.join(TMP_DIR, file_name.split(\".\")[0])\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        # Detect all faces appear in the video and save them.\n",
    "        face_extractor(path, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pruth\\\\Desktop\\\\New folder\\\\Test\\\\Temp\\\\001'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "s = os.getcwd()+\"\\\\Test\\\\001\"\n",
    "d = os.getcwd()+\"\\\\Test\\\\Temp\\\\001\"\n",
    "shutil.move(s,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+'\\\\test\\\\Temp'\n",
    "import cv2\n",
    "test_data_X = list()\n",
    "num1 = 256\n",
    "num2 = 256\n",
    "for fold in os.listdir(path):\n",
    "    new_path = os.path.join(path, fold)\n",
    "    c = 0\n",
    "    for frames in os.listdir(new_path):\n",
    "        if(c == 150):\n",
    "            break\n",
    "        c = c + 1\n",
    "        path_a = os.path.join(new_path,frames)\n",
    "        img = cv2.imread(path_a)\n",
    "        new_img = cv2.resize(img, (num2, num1))\n",
    "        test_data_X.append(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 256, 256, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_data_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE\n"
     ]
    }
   ],
   "source": [
    "classifier4 = load_model('Mesonet_4_Model.h5')\n",
    "test_data_X = np.array(test_data_X)\n",
    "predictions = classifier4.predict(test_data_X)\n",
    "result = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >=0.5:\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(0)\n",
    "if result.count(1)>=result.count(0):\n",
    "    print(\"REAL\")\n",
    "else:\n",
    "    print(\"FAKE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
